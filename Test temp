awk '
/^[0-9]{2}-[A-Z]{3}-[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2}/ {
    # Capture the timestamp
    timestamp = $0
}

/Elapsed:/ {
    # Capture and print the elapsed time with the corresponding timestamp
    print timestamp " ——— " $0
}
' your_log_file.log




WITH Partition_Data AS (
    SELECT 
        TABLE_NAME,
        PARTITION_NAME,
        TO_DATE(
            TRIM('TO_DATE(' FROM HIGH_VALUE), 
            'YYYY-MM-DD'
        ) AS PARTITION_DATE
    FROM 
        DBA_TAB_PARTITIONS
    WHERE 
        TABLE_NAME = 'YOUR_TABLE_NAME'
)
SELECT * 
FROM Partition_Data
WHERE PARTITION_DATE = TO_DATE('2024-12-13', 'YYYY-MM-DD');


SET SERVEROUTPUT ON
DECLARE
    v_joindate VARCHAR2(4000); -- Variable to hold the converted LONG value
    v_today    DATE := SYSDATE; -- Today's date
BEGIN
    FOR rec IN (
        SELECT EMPID, TO_LOB(JOINDATE) AS JOINDATE_RAW
        FROM EMPLOYEES
    ) LOOP
        BEGIN
            -- Attempt to convert the LONG value to a date dynamically
            EXECUTE IMMEDIATE 'SELECT ' || rec.JOINDATE_RAW || ' FROM DUAL' INTO v_joindate;
            
            -- Compare with today's date
            IF TO_DATE(v_joindate, 'YYYY-MM-DD') = TRUNC(v_today) THEN
                DBMS_OUTPUT.PUT_LINE('EmpID: ' || rec.EMPID || ' joined today.');
            END IF;
        EXCEPTION
            WHEN OTHERS THEN
                DBMS_OUTPUT.PUT_LINE('Error processing JOINDATE for EmpID: ' || rec.EMPID);
        END;
    END LOOP;
END;
/








-- 1. RAC-aware Tablespace Usage Analysis (in GB)
SELECT 
    t.TABLESPACE_NAME,
    t.STATUS,
    t.CONTENTS,
    TO_CHAR(ROUND(SUM(d.BYTES) / 1024 / 1024 / 1024, 2), '999,999.99') || ' GB' AS TOTAL_SIZE,
    TO_CHAR(ROUND((SUM(d.BYTES) - NVL(SUM(f.BYTES), 0)) / 1024 / 1024 / 1024, 2), '999,999.99') || ' GB' AS USED_SPACE,
    TO_CHAR(ROUND(NVL(SUM(f.BYTES), 0) / 1024 / 1024 / 1024, 2), '999,999.99') || ' GB' AS FREE_SPACE,
    ROUND((SUM(d.BYTES) - NVL(SUM(f.BYTES), 0)) / SUM(d.BYTES) * 100, 2) || '%' AS USED_PCT,
    d.STATUS AS DATAFILE_STATUS
FROM 
    DBA_TABLESPACES t,
    DBA_DATA_FILES d,
    DBA_FREE_SPACE f
WHERE 
    t.TABLESPACE_NAME = d.TABLESPACE_NAME
    AND d.TABLESPACE_NAME = f.TABLESPACE_NAME (+)
    AND d.FILE_ID = f.FILE_ID (+)
GROUP BY 
    t.TABLESPACE_NAME,
    t.STATUS,
    t.CONTENTS,
    d.STATUS
ORDER BY 
    t.TABLESPACE_NAME;

-- 2. RAC Instance-specific Temporary Tablespace Usage (in GB)
SELECT 
    gi.INSTANCE_NAME,
    gi.HOST_NAME,
    tt.TABLESPACE_NAME,
    TO_CHAR(ROUND(SUM(tt.BYTES_USED)/1024/1024/1024, 2), '999,999.99') || ' GB' AS TEMP_USED,
    TO_CHAR(ROUND(SUM(tt.BYTES_FREE)/1024/1024/1024, 2), '999,999.99') || ' GB' AS TEMP_FREE,
    ROUND((SUM(tt.BYTES_USED) / (SUM(tt.BYTES_USED) + SUM(tt.BYTES_FREE))) * 100, 2) || '%' AS USED_PCT
FROM 
    GV$TEMP_SPACE_HEADER tt
    JOIN GV$INSTANCE gi ON tt.INST_ID = gi.INST_ID
GROUP BY 
    gi.INSTANCE_NAME,
    gi.HOST_NAME,
    tt.TABLESPACE_NAME
ORDER BY 
    gi.INSTANCE_NAME,
    tt.TABLESPACE_NAME;

-- 3. Historical Growth Analysis for RAC (Date Range Based, in GB)
WITH snapshot_ranges AS (
    SELECT 
        snap_id,
        instance_number,
        begin_interval_time,
        end_interval_time
    FROM 
        DBA_HIST_SNAPSHOT
    WHERE 
        begin_interval_time >= TO_DATE('&start_date', 'YYYY-MM-DD')
        AND end_interval_time <= TO_DATE('&end_date', 'YYYY-MM-DD')
)
SELECT 
    s.instance_number,
    i.instance_name,
    i.host_name,
    t.TABLESPACE_NAME,
    TO_CHAR(s.begin_interval_time, 'YYYY-MM-DD HH24:MI') AS SNAPSHOT_TIME,
    TO_CHAR(ROUND(SUM(u.TABLESPACE_SIZE * ts.BLOCK_SIZE / 1024 / 1024 / 1024), 2), '999,999.99') || ' GB' AS TOTAL_SIZE,
    TO_CHAR(ROUND(SUM(u.TABLESPACE_USEDSIZE * ts.BLOCK_SIZE / 1024 / 1024 / 1024), 2), '999,999.99') || ' GB' AS USED_SIZE,
    ROUND(SUM(u.TABLESPACE_USEDSIZE)/SUM(u.TABLESPACE_SIZE) * 100, 2) || '%' AS USED_PCT
FROM 
    DBA_HIST_TBSPC_SPACE_USAGE u
    JOIN snapshot_ranges s ON u.SNAP_ID = s.snap_id
    JOIN GV$INSTANCE i ON s.instance_number = i.INSTANCE_NUMBER
    JOIN V$TABLESPACE v ON u.TABLESPACE_ID = v.TS#
    JOIN DBA_TABLESPACES t ON v.NAME = t.TABLESPACE_NAME
    JOIN DBA_TABLESPACES ts ON t.TABLESPACE_NAME = ts.TABLESPACE_NAME
GROUP BY 
    s.instance_number,
    i.instance_name,
    i.host_name,
    t.TABLESPACE_NAME,
    s.begin_interval_time
ORDER BY 
    s.instance_number,
    t.TABLESPACE_NAME,
    s.begin_interval_time;

-- 4. ASM Diskgroup Usage in GB (if using ASM)
SELECT 
    g.NAME AS DISKGROUP_NAME,
    g.STATE,
    g.TYPE,
    ROUND(g.TOTAL_MB/1024, 2) || ' GB' AS TOTAL_SPACE,
    ROUND(g.FREE_MB/1024, 2) || ' GB' AS FREE_SPACE,
    TO_CHAR(ROUND((g.TOTAL_MB - g.FREE_MB)/1024, 2), '999,999.99') || ' GB' AS USED_SPACE,
    ROUND(((g.TOTAL_MB - g.FREE_MB)/g.TOTAL_MB) * 100, 2) || '%' AS USED_PCT,
    ROUND(g.REQUIRED_MIRROR_FREE_MB/1024, 2) || ' GB' AS REQUIRED_MIRROR_FREE,
    ROUND(g.USABLE_FILE_MB/1024, 2) || ' GB' AS USABLE_SPACE
FROM 
    V$ASM_DISKGROUP g
ORDER BY 
    g.NAME;

-- 5. UNDO Tablespace Usage per Instance (in GB)
SELECT 
    i.INST_ID,
    i.INSTANCE_NAME,
    i.HOST_NAME,
    u.TABLESPACE_NAME,
    TO_CHAR(ROUND(SUM(d.BYTES)/1024/1024/1024, 2), '999,999.99') || ' GB' AS TOTAL_SPACE,
    TO_CHAR(ROUND((SUM(d.BYTES) - NVL(SUM(f.BYTES), 0))/1024/1024/1024, 2), '999,999.99') || ' GB' AS USED_SPACE,
    ROUND(((SUM(d.BYTES) - NVL(SUM(f.BYTES), 0))/SUM(d.BYTES)) * 100, 2) || '%' AS USED_PCT
FROM 
    GV$INSTANCE i
    JOIN DBA_TABLESPACES u ON u.CONTENTS = 'UNDO'
    JOIN DBA_DATA_FILES d ON u.TABLESPACE_NAME = d.TABLESPACE_NAME
    LEFT JOIN DBA_FREE_SPACE f ON d.TABLESPACE_NAME = f.TABLESPACE_NAME AND d.FILE_ID = f.FILE_ID
GROUP BY 
    i.INST_ID,
    i.INSTANCE_NAME,
    i.HOST_NAME,
    u.TABLESPACE_NAME
ORDER BY 
    i.INST_ID,
    u.TABLESPACE_NAME;







------------
For Oracle databases, you can use the following queries to identify which processes are consuming high CPU:

1. **Check current active sessions with CPU usage**:
```sql
SELECT s.sid, s.serial#, s.username, s.osuser, 
       s.program, sq.sql_id, sq.sql_text,
       st.value/100 as CPU_SECONDS
FROM v$session s
JOIN v$sesstat st ON s.sid = st.sid
JOIN v$statname sn ON st.statistic# = sn.statistic#
LEFT JOIN v$sql sq ON s.sql_id = sq.sql_id
WHERE sn.name = 'CPU used by this session'
AND st.value > 0
ORDER BY st.value DESC;
```

2. **Identify top SQL statements by CPU usage**:
```sql
SELECT sql_id, sql_text, 
       cpu_time/1000000 as CPU_SECONDS, 
       elapsed_time/1000000 as ELAPSED_SECONDS,
       executions, 
       cpu_time/NULLIF(executions,0)/1000000 as CPU_SECONDS_PER_EXEC
FROM v$sql
ORDER BY cpu_time DESC
FETCH FIRST 20 ROWS ONLY;
```

3. **Check for resource-intensive operations**:
```sql
SELECT sid, serial#, username, opname, target, 
       sofar, totalwork, 
       ROUND(sofar/totalwork*100, 2) as "% Complete",
       elapsed_seconds, time_remaining
FROM v$session_longops
WHERE sofar < totalwork
ORDER BY elapsed_seconds DESC;
```

4. **Monitor OS process information**:
```sql
SELECT p.spid as OS_PID, s.sid, s.serial#, s.username, 
       s.status, s.last_call_et as SECONDS_IN_CURRENT_STATE,
       s.sql_id, s.event, s.wait_class
FROM v$process p
JOIN v$session s ON p.addr = s.paddr
WHERE s.type = 'USER'
ORDER BY s.last_call_et DESC;
```

Once you identify problematic sessions, you can get more details on a specific SQL statement:
```sql
SELECT * FROM v$sql WHERE sql_id = 'your_sql_id_here';
```

Or terminate a problematic session if necessary:
```sql
ALTER SYSTEM KILL SESSION 'sid,serial#' IMMEDIATE;
```

Would you like more specific information on interpreting these results or additional queries for deeper diagnosis?​​​​​​​​​​​​​​​​





======••====
SELECT
    o.owner,
    o.object_name AS table_name,
    COUNT(DISTINCT s.sql_id) AS sql_count,
    SUM(ss.executions_delta) AS total_executions
FROM
    dba_hist_sqlstat ss
JOIN
    dba_hist_sqltext s ON ss.sql_id = s.sql_id
JOIN
    dba_objects o ON s.sql_text LIKE '%' || o.object_name || '%'
WHERE
    o.owner IN ('SBINRT82', 'SBINRTFO', 'SBIARUSER', 'SBINRTCINB')
    AND o.object_name IN (
        'PRM_REF_DATA_LISTS',
        'DE_RECORD_SOURCE_ATTR',
        'AR_UI_VIEW_ELEMENT',
        'AR_UI_ELEMENT_CONFIG'
    )
GROUP BY
    o.owner, o.object_name
ORDER BY
    total_executions DESC;
==============================================================



Good — your checklist is quite solid and already covers the main migration flow (FAR, RMAN, standby setup, incremental sync, GoldenGate, etc.).
However, I can suggest a few practical improvements and missing steps, especially around network connectivity, Data Guard / DR, and post-migration validation. Here’s a reviewed and slightly reorganized version:

⸻

✅ Migration Checklist: Exadata X4 → X7

Sr. No.	Action	Team	Approx. Time / Notes
1	Confirm FAR (Fast Application Recovery) and network connectivity between Exadata X4, X7, and DR servers (test ping, tns, scp).	DBA / Network	1–2 hrs
2	Confirm connectivity between App Servers ↔ X7 DB, X7 ↔ DR, and backup network links.	DBA / Network	1 hr
3	Validate DNS entries, SCAN, VIP, and listener configuration for X7 cluster.	DBA	1–2 hrs
4	Confirm storage availability, ASM disk group layout, and DB home versions on X7.	DBA	1–2 hrs
5	Take full RMAN backup of X4 production DB.	DBA	7–8 hrs
6	Transfer RMAN backup to X7 and restore + recover standby database.	DBA	2–3 days (based on data size)
7	Create standby instance and configuration on X7.	DBA	5–6 hrs
8	Start incremental backup sync from X4 → X7 standby (using SCN-based incremental RMAN backup).	DBA	Depends on delta size
9	Verify Data Guard / redo transport to DR site from X7 once standby is active.	DBA	1–2 hrs
10	Configure GoldenGate replication (if used for cutover or validation).	DBA	Required down
11	Application team testing on X7 standby (post-sync read-only mode).	App Team	As required
12	Perform Switchover to X7 (make X7 primary).	DBA	Downtime window
13	Validate Data Guard configuration – confirm redo transport from X7 primary to DR site.	DBA	1–2 hrs
14	Start GoldenGate replication post-cutover (if bi-directional sync used).	DBA	—
15	Post-migration validation: check DB links, jobs, directory objects, ACLs, and connectivity from all app servers.	DBA / App	2–3 hrs
16	Monitor performance, AWR baselines, and redo lag for first 24 hrs.	DBA	Continuous


⸻

⚙️ Additional Suggestions:
	1.	Connectivity Checks
	•	Verify SCAN name resolution (nslookup, srvctl config scan).
	•	Confirm ports open between X4 ↔ X7 ↔ DR (1521, 22, GG ports if used).
	•	Test tnsping and sqlplus connections before RMAN operations.
	2.	DR (Data Guard) Validation
	•	After switchover, ensure DR now receives logs from the new X7 primary.
	•	Validate v$dataguard_stats, transport lag, and apply lag.
	3.	Backup Strategy
	•	Take final RMAN backup post-switchover from X7 primary.
	•	Ensure new catalog registration if using RMAN catalog.
	4.	GoldenGate
	•	If GoldenGate is used for near-zero downtime migration, ensure GG version compatibility and proper parameter file update for new DB SID and TNS.
	5.	Cutover Plan
	•	Schedule exact downtime window for final sync and switchover.
	•	Ensure rollback plan (X4 still available until X7 validated).
	6.	Post Migration Cleanup
	•	Decommission X4 standby and remove old entries from listener, TNS, GG params, etc.

⸻

If you want, I can draft this in a tabular Excel-ready format (so you can directly paste it into your sheet with your original layout). Would you like me to prepare that version?








